{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:25:05.235277Z",
     "start_time": "2025-07-08T18:25:03.921801Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:25:29.490704Z",
     "start_time": "2025-07-08T18:25:10.152981Z"
    }
   },
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"basic\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:30:36.394878Z",
     "start_time": "2025-07-08T18:30:35.915911Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:27:59.527540Z",
     "start_time": "2025-07-08T18:27:56.231477Z"
    }
   },
   "source": [
    "df = spark.read.csv(\"D:\\Business Analytics\\Data Visualization\\Power BI\\Power BI DAX\\Section 1\\Customers.csv\", header=True, inferSchema=True)"
   ],
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/D:/Business Analytics/Data Visualization/Power BI/Power BI DAX/Section 1/Customers.csv.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mD:\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mBusiness Analytics\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mData Visualization\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mPower BI\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mPower BI DAX\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mSection 1\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mCustomers.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minferSchema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive - ConcertAI\\Python\\PySpark\\venv\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:740\u001B[0m, in \u001B[0;36mDataFrameReader.csv\u001B[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001B[0m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[0;32m    739\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 740\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_spark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, RDD):\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc\u001B[39m(iterator):\n",
      "File \u001B[1;32m~\\OneDrive - ConcertAI\\Python\\PySpark\\venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[1;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\OneDrive - ConcertAI\\Python\\PySpark\\venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mAnalysisException\u001B[0m: [PATH_NOT_FOUND] Path does not exist: file:/D:/Business Analytics/Data Visualization/Power BI/Power BI DAX/Section 1/Customers.csv."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|BirthDate|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+\n",
      "|      11000|   MR.|    PAVAN| LALWANI| 4/8/1996|            M|     M|jon24@adventure-w...|    $90,000 |            2|     Bachelors|Professional|        Y|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|5/14/1965|            S|     M|eugene10@adventur...|    $60,000 |            3|     Bachelors|Professional|        N|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|8/12/1965|            M|     M|ruben35@adventure...|    $60,000 |            3|     Bachelors|Professional|        Y|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|2/15/1968|            S|     F|christy12@adventu...|    $70,000 |            0|     Bachelors|Professional|        N|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON| 8/8/1968|            S|     F|elizabeth5@advent...|    $80,000 |            5|     Bachelors|Professional|        Y|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the datatype of BirthDate to Date\n",
    "\n",
    "df_new = df.withColumn(\"DOB\", col(\"BirthDate\").cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----+\n",
      "|CustomerKey|Prefix|FirstName|LastName|BirthDate|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner| DOB|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----+\n",
      "|      11000|   MR.|    PAVAN| LALWANI| 4/8/1996|            M|     M|jon24@adventure-w...|    $90,000 |            2|     Bachelors|Professional|        Y|NULL|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|5/14/1965|            S|     M|eugene10@adventur...|    $60,000 |            3|     Bachelors|Professional|        N|NULL|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|8/12/1965|            M|     M|ruben35@adventure...|    $60,000 |            3|     Bachelors|Professional|        Y|NULL|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|2/15/1968|            S|     F|christy12@adventu...|    $70,000 |            0|     Bachelors|Professional|        N|NULL|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON| 8/8/1968|            S|     F|elizabeth5@advent...|    $80,000 |            5|     Bachelors|Professional|        Y|NULL|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.withColumn(\"DOB\", to_date(col(\"BirthDate\"), \"M/d/yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|BirthDate|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner|       DOB|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|      11000|   MR.|    PAVAN| LALWANI| 4/8/1996|            M|     M|jon24@adventure-w...|    $90,000 |            2|     Bachelors|Professional|        Y|1996-04-08|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|5/14/1965|            S|     M|eugene10@adventur...|    $60,000 |            3|     Bachelors|Professional|        N|1965-05-14|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|8/12/1965|            M|     M|ruben35@adventure...|    $60,000 |            3|     Bachelors|Professional|        Y|1965-08-12|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|2/15/1968|            S|     F|christy12@adventu...|    $70,000 |            0|     Bachelors|Professional|        N|1968-02-15|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON| 8/8/1968|            S|     F|elizabeth5@advent...|    $80,000 |            5|     Bachelors|Professional|        Y|1968-08-08|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerKey: integer (nullable = true)\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- BirthDate: string (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- EmailAddress: string (nullable = true)\n",
      " |-- AnnualIncome: string (nullable = true)\n",
      " |-- TotalChildren: integer (nullable = true)\n",
      " |-- EducationLevel: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- HomeOwner: string (nullable = true)\n",
      " |-- DOB: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(\"BirthDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner|       DOB|\n",
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|      11000|   MR.|    PAVAN| LALWANI|            M|     M|jon24@adventure-w...|    $90,000 |            2|     Bachelors|Professional|        Y|1996-04-08|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|            S|     M|eugene10@adventur...|    $60,000 |            3|     Bachelors|Professional|        N|1965-05-14|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|            M|     M|ruben35@adventure...|    $60,000 |            3|     Bachelors|Professional|        Y|1965-08-12|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|            S|     F|christy12@adventu...|    $70,000 |            0|     Bachelors|Professional|        N|1968-02-15|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON|            S|     F|elizabeth5@advent...|    $80,000 |            5|     Bachelors|Professional|        Y|1968-08-08|\n",
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|MaritalStatus|\n",
      "+-------------+\n",
      "|            M|\n",
      "|            S|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.select(col(\"MaritalStatus\")).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.withColumn(\"MaritalStatus\", when(col(\"MaritalStatus\") == \"M\", \"Married\").otherwise(\"Single\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.withColumn(\"AnnualIncome\", regexp_replace(\"AnnualIncome\", \"[$,]\", \"\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerKey: integer (nullable = true)\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = false)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- EmailAddress: string (nullable = true)\n",
      " |-- AnnualIncome: integer (nullable = true)\n",
      " |-- TotalChildren: integer (nullable = true)\n",
      " |-- EducationLevel: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- HomeOwner: string (nullable = true)\n",
      " |-- DOB: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_col = [\"MaritalStatus\",\"Occupation\",\"EducationLevel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------------+--------------+------------+\n",
      "|MaritalStatus|    Occupation|     EducationLevel|Total Customer|Total Income|\n",
      "+-------------+--------------+-------------------+--------------+------------+\n",
      "|       Single|        Manual|          Bachelors|            29|      330000|\n",
      "|      Married|      Clerical|    Graduate Degree|           288|     9120000|\n",
      "|      Married|  Professional|          Bachelors|           814|    56430000|\n",
      "|       Single|        Manual|        High School|           655|    12680000|\n",
      "|       Single|    Management|          Bachelors|           575|    51340000|\n",
      "|      Married|Skilled Manual|Partial High School|           207|    13300000|\n",
      "|       Single|      Clerical|    Partial College|           729|    24390000|\n",
      "|       Single|    Management|        High School|           105|    11400000|\n",
      "|      Married|    Management|    Graduate Degree|           628|    54960000|\n",
      "|       Single|Skilled Manual|Partial High School|           150|    10210000|\n",
      "|      Married|        Manual|    Graduate Degree|            37|      420000|\n",
      "|       Single|    Management|    Partial College|            27|     3280000|\n",
      "|       Single|    Management|    Graduate Degree|           411|    38610000|\n",
      "|       Single|    Management|Partial High School|             5|      640000|\n",
      "|      Married|      Clerical|        High School|            49|     1470000|\n",
      "|       Single|Skilled Manual|        High School|           467|    19220000|\n",
      "|      Married|    Management|    Partial College|            58|     7050000|\n",
      "|      Married|Skilled Manual|    Graduate Degree|           410|    23190000|\n",
      "|      Married|Skilled Manual|        High School|           553|    19420000|\n",
      "|       Single|  Professional|        High School|           351|    24940000|\n",
      "+-------------+--------------+-------------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.groupBy(group_by_col)\\\n",
    "    .agg(\n",
    "        countDistinct(\"CustomerKey\").alias(\"Total Customer\"),\n",
    "        sum(\"AnnualIncome\").alias(\"Total Income\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------+\n",
      "|    Occupation|Total Customer|Total Income|\n",
      "+--------------+--------------+------------+\n",
      "|  Professional|          5424|   402280000|\n",
      "|    Management|          3011|   277670000|\n",
      "|Skilled Manual|          4501|   232850000|\n",
      "|      Clerical|          2859|    87760000|\n",
      "|        Manual|          2353|    38760000|\n",
      "+--------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.groupBy(\"Occupation\")\\\n",
    "    .agg(\n",
    "        countDistinct(\"CustomerKey\").alias(\"Total Customer\"),\n",
    "        sum(\"AnnualIncome\").alias(\"Total Income\")\n",
    "    ).sort(desc(\"Total Income\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.createTempView(\"customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_result = spark.sql(\"\"\"Select * from {tab} LIMIT {lim}\"\"\".format(tab = \"customer\", lim = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner|       DOB|\n",
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "|      11000|   MR.|    PAVAN| LALWANI|      Married|     M|jon24@adventure-w...|       90000|            2|     Bachelors|Professional|        Y|1996-04-08|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|       Single|     M|eugene10@adventur...|       60000|            3|     Bachelors|Professional|        N|1965-05-14|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|      Married|     M|ruben35@adventure...|       60000|            3|     Bachelors|Professional|        Y|1965-08-12|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|       Single|     F|christy12@adventu...|       70000|            0|     Bachelors|Professional|        N|1968-02-15|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON|       Single|     F|elizabeth5@advent...|       80000|            5|     Bachelors|Professional|        Y|1968-08-08|\n",
      "+-----------+------+---------+--------+-------------+------+--------------------+------------+-------------+--------------+------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window, WindowSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.window.WindowSpec"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WindowSpec.orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_spec = Window.partitionBy(\"Occupation\", \"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.withColumn(\"MaxSalary\", max(\"AnnualIncome\").over(win_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+----------+-------------+------+--------------------+------------+-------------+-------------------+----------+---------+----------+-------+---------+\n",
      "|CustomerKey|Prefix|FirstName|  LastName|MaritalStatus|Gender|        EmailAddress|AnnualIncome|TotalChildren|     EducationLevel|Occupation|HomeOwner|       DOB|row_num|MaxSalary|\n",
      "+-----------+------+---------+----------+-------------+------+--------------------+------------+-------------+-------------------+----------+---------+----------+-------+---------+\n",
      "|      11037|   MS.|    CHLOE|    GARCIA|       Single|     F|chloe27@adventure...|       40000|            0|Partial High School|  Clerical|        N|1977-11-27|      1|    40000|\n",
      "|      11049|   MS.|    CAROL|       RAI|       Single|     F|carol8@adventure-...|       40000|            0|Partial High School|  Clerical|        Y|1980-07-18|      2|    40000|\n",
      "|      11052|  MRS.|    HEIDI|     LOPEZ|       Single|     F|heidi19@adventure...|       40000|            2|    Partial College|  Clerical|        N|1951-08-07|      3|    40000|\n",
      "|      11387|  MRS.|    MEGAN|   RAMIREZ|       Single|     F|megan44@adventure...|       40000|            3|    Graduate Degree|  Clerical|        Y|1959-06-02|      4|    40000|\n",
      "|      11401|   MS.|    LINDA|   NAVARRO|      Married|     F|linda25@adventure...|       40000|            0|    Graduate Degree|  Clerical|        Y|1969-08-26|      5|    40000|\n",
      "|      11402|   MS.|    KELLI|       CAI|      Married|     F|kelli21@adventure...|       40000|            0|    Graduate Degree|  Clerical|        Y|1969-11-20|      6|    40000|\n",
      "|      11403|   MS.|    NANCY|   SCHMIDT|       Single|     F|nancy13@adventure...|       40000|            0|    Graduate Degree|  Clerical|        Y|1969-01-09|      7|    40000|\n",
      "|      11493|  MRS.|     DAWN|        WU|       Single|     F|dawn8@adventure-w...|       40000|            2|    Partial College|  Clerical|        Y|1970-12-02|      8|    40000|\n",
      "|      11497|  MRS.|  KATRINA|      NATH|       Single|     F|katrina17@adventu...|       40000|            2|    Partial College|  Clerical|        Y|1970-11-26|      9|    40000|\n",
      "|      11501|  MRS.|   BRANDY|   CHANDRA|       Single|     F|brandy20@adventur...|       40000|            3|    Partial College|  Clerical|        Y|1975-07-07|     10|    40000|\n",
      "|      11517|  MRS.|KATHERINE|    BRYANT|      Married|     F|katherine44@adven...|       40000|            1|    Partial College|  Clerical|        Y|1954-06-20|     11|    40000|\n",
      "|      11520|  MRS.|     JADA|    MORGAN|      Married|     F|jada14@adventure-...|       40000|            1|    Partial College|  Clerical|        Y|1955-04-11|     12|    40000|\n",
      "|      11521|  MRS.|   ARIANA|  PETERSON|      Married|     F|ariana4@adventure...|       40000|            1|    Partial College|  Clerical|        Y|1955-12-09|     13|    40000|\n",
      "|      11524|  MRS.|   ALYSSA|   JACKSON|      Married|     F|alyssa11@adventur...|       40000|            1|    Partial College|  Clerical|        Y|1956-01-23|     14|    40000|\n",
      "|      11525|  MRS.|   ARIANA|      COOK|      Married|     F|ariana19@adventur...|       40000|            1|    Partial College|  Clerical|        Y|1956-01-09|     15|    40000|\n",
      "|      11527|  MRS.|    JENNA|     GREEN|      Married|     F|jenna14@adventure...|       40000|            1|    Partial College|  Clerical|        Y|1956-06-04|     16|    40000|\n",
      "|      11528|  MRS.|     JOAN|WASHINGTON|      Married|     F|joan7@adventure-w...|       40000|            1|    Partial College|  Clerical|        Y|1957-08-19|     17|    40000|\n",
      "|      11531|  MRS.|     NINA|      YUAN|      Married|     F|nina7@adventure-w...|       40000|            1|    Partial College|  Clerical|        Y|1957-01-07|     18|    40000|\n",
      "|      11532|  MRS.|   LAUREN|    MILLER|      Married|     F|lauren24@adventur...|       40000|            1|    Partial College|  Clerical|        Y|1957-02-26|     19|    40000|\n",
      "|      11533|  MRS.|    EBONY|      GILL|      Married|     F|ebony35@adventure...|       40000|            1|    Partial College|  Clerical|        Y|1957-07-21|     20|    40000|\n",
      "+-----------+------+---------+----------+-------------+------+--------------------+------------+-------------+-------------------+----------+---------+----------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
